# Previs√£o de Consumo de Energia El√©trica no Brasil com Redes LSTM  

Este projeto tem como objetivo prever o consumo de energia el√©trica no Brasil utilizando Redes Neurais Recorrentes (LSTM). O reposit√≥rio documenta todas as etapas de uma pipeline de Machine Learning, incluindo an√°lise explorat√≥ria, tratamento de dados, descri√ß√£o da arquitetura do modelo e apresenta√ß√£o dos resultados.

---

## üìå **Introdu√ß√£o**  
A previs√£o do consumo de energia el√©trica √© essencial para o planejamento e a opera√ß√£o eficiente do setor energ√©tico. A capacidade de prever o consumo futuro permite:  
- Melhor gerenciamento dos recursos energ√©ticos.  
- Redu√ß√£o de custos operacionais.  
- Minimiza√ß√£o de impactos ambientais.  

Este projeto utiliza dados hist√≥ricos de consumo mensal de energia el√©trica no Brasil para criar um modelo que antecipa tend√™ncias e sazonalidades, otimizando a tomada de decis√µes no setor.

---

## üìä **Fonte dos Dados**  

Os dados utilizados no projeto foram obtidos da [Base dos Dados](https://basedosdados.org/dataset/3e31e540-81ba-4665-9e72-3f81c176adad?table=b955feef-1649-428b-ba46-bc891d2facc2).  

- **Organiza√ß√£o**: Minist√©rio de Minas e Energia (MME).  
- **Cobertura temporal**: Janeiro/2004 a Dezembro/2023.  
- **Descri√ß√£o**: Dados mensais do consumo de energia el√©trica na rede (MWh), separados por classes (residencial, industrial, comercial, etc.).  

---

# Previs√£o de Consumo de Energia El√©trica no Brasil  

Este projeto utiliza uma pipeline de Machine Learning para prever o consumo de energia el√©trica no Brasil. Aqui, descrevemos o processo de tratamento e prepara√ß√£o dos dados, que √© uma etapa fundamental para garantir a qualidade do modelo e a precis√£o das previs√µes.

---

## üîÑ **Tratamento dos Dados**  

Foi realizado um filtro para selecionar apenas o tipo de **consumo residencial**, visto que o objetivo √© focar neste segmento espec√≠fico.

A filtragem foi feita da seguinte forma:

### **Etapas de Pr√©-processamento**  

1. **Filtragem por Tipo de Consumo Residencial**  
   Selecionamos apenas os dados onde o tipo de consumo √© classificado como "Residencial".  
   ```python
   df_residencial = df[df['tipo_consumo'] == 'Residencial']
   print(df_residencial.shape)  # (6480, 6)

### **2. Agrega√ß√£o Mensal dos Dados**  

Para facilitar a an√°lise e modelagem, os dados foram agrupados por **ano** e **m√™s**, somando o consumo total e o n√∫mero de consumidores. 

```python
df_brasil = df_residencial.groupby(['ano', 'mes']).agg({
    'consumo': 'sum',
    'numero_consumidores': 'sum'
}).reset_index()
```
![tabela](assets/1.png)

### **3. Convers√£o de Datas**  

Foi criada uma coluna de datas a partir do ano e m√™s, utilizando o primeiro dia de cada m√™s como refer√™ncia. Essa coluna foi definida como √≠ndice para organizar os dados como uma s√©rie temporal. 

```python
df_brasil['data'] = pd.to_datetime(dict(year=df_brasil['ano'], month=df_brasil['mes'], day=1))
df_brasil = df_brasil.set_index('data').drop(['ano', 'mes'], axis=1)
```
![tabela2](assets/2.png)

### ‚öñÔ∏è **Normaliza√ß√£o dos Dados**

A normaliza√ß√£o foi aplicada nas colunas de **consumo** e **n√∫mero de consumidores** utilizando o **MinMaxScaler** para escalonar os valores entre 0 e 1. Isso ajuda a melhorar o desempenho dos modelos de redes neurais, que geralmente se beneficiam quando os dados est√£o em uma faixa similar. 

```python
scalers = {}
for column in ['consumo', 'numero_consumidores']:
    scaler = MinMaxScaler()
    df_brasil[column] = scaler.fit_transform(df_brasil[[column]])
    scalers[column] = scaler
```

# ü§ñ Descri√ß√£o do Modelo

As Redes Neurais Recorrentes LSTM s√£o uma arquitetura espec√≠fica de RNNs que possuem a capacidade de aprender depend√™ncias de longo prazo em sequ√™ncias temporais. Elas s√£o ideais para tarefas como previs√£o de s√©ries temporais, onde as depend√™ncias entre os dados n√£o se limitam a curtos per√≠odos de tempo, mas sim a padr√µes que podem se estender por dias, semanas ou at√© meses.

## Por que usar LSTM para previs√µes de s√©ries temporais?

- **Capacidade de Capturar Depend√™ncias de Longo Prazo**: As LSTMs podem manter informa√ß√µes ao longo de v√°rias etapas de tempo, permitindo que elas aprendam padr√µes sazonais e tend√™ncias de longo prazo, o que √© essencial em s√©ries temporais como o consumo de energia.
  
- **Manejo de Gradientes Explosivos ou Desaparecendo**: Uma das limita√ß√µes das RNNs convencionais √© o problema dos gradientes explosivos ou desaparecendo durante o treinamento. LSTMs resolvem isso utilizando uma c√©lula de mem√≥ria que controla o fluxo de informa√ß√µes ao longo do tempo, garantindo uma aprendizagem mais est√°vel.

- **Solu√ß√µes para S√©ries Temporais N√£o Lineares**: O consumo de energia el√©trica pode ser afetado por uma s√©rie de fatores complexos, como clima, feriados e tend√™ncias econ√¥micas. As LSTMs podem lidar com essas n√£o linearidades de forma eficiente.

## Arquitetura da Rede LSTM

A arquitetura do modelo LSTM foi configurada da seguinte maneira:

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dropout, Dense

model = Sequential()

# Camada LSTM com 50 unidades e ativa√ß√£o 'tanh'
# 'input_shape' define as dimens√µes da entrada (n_steps, features)
# 'return_sequences=False' garante que a sa√≠da seja uma √∫nica previs√£o
model.add(LSTM(50, activation='tanh', return_sequences=False, input_shape=(n_steps, 2)))

# Camada de Dropout para evitar overfitting
model.add(Dropout(0.2))

# Camada densa com 1 unidade e ativa√ß√£o linear, ideal para tarefas de regress√£o
model.add(Dense(1, activation='linear'))

# Compila√ß√£o do modelo com otimizador 'adam' e loss 'mse' (erro quadr√°tico m√©dio)
model.compile(optimizer='adam', loss='mse')
```
## Explica√ß√£o da Arquitetura

### Camada LSTM:

- A camada LSTM foi configurada com 50 unidades. A ativa√ß√£o utilizada √© a `tanh`, que √© comum em LSTMs e ajuda a regular os valores dos neur√¥nios.
- `input_shape=(n_steps, 2)`: O modelo recebe dados de s√©ries temporais com `n_steps` de tempo e 2 caracter√≠sticas de entrada (por exemplo, consumo de energia e temperatura).
- `return_sequences=False`: Configurado para retornar apenas a sa√≠da final da sequ√™ncia (isto √©, uma √∫nica previs√£o), e n√£o as sa√≠das intermedi√°rias.

### Camada Dropout:

- A camada de Dropout √© usada para reduzir o overfitting durante o treinamento, "desligando" aleatoriamente uma fra√ß√£o dos neur√¥nios (20% neste caso). Isso ajuda o modelo a generalizar melhor.

### Camada Densa:

- A camada final √© uma camada densa com 1 unidade e ativa√ß√£o linear, ideal para tarefas de regress√£o, onde a sa√≠da do modelo √© um valor cont√≠nuo (neste caso, a previs√£o do consumo de energia).

### Compila√ß√£o do Modelo:

- O modelo √© compilado utilizando o otimizador Adam (um dos mais populares para problemas de s√©ries temporais) e o erro quadr√°tico m√©dio (MSE) como a fun√ß√£o de perda, pois estamos lidando com uma tarefa de regress√£o.

## üë®‚Äçüè´ Treinamento do Modelo 

O treinamento do modelo √© realizado utilizando o m√©todo `fit` do Keras. 

```python
history = model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.1)
```

## Par√¢metros:

- **X_train**: Conjunto de dados de entrada de treinamento. √â um array de s√©ries temporais com caracter√≠sticas (exemplo: consumo de energia e temperatura) e etapas de tempo.

- **y_train**: R√≥tulos ou valores de sa√≠da correspondentes aos dados de treinamento. Neste caso, √© a vari√°vel que estamos tentando prever (por exemplo, o consumo de energia futuro).

- **epochs=50**: O n√∫mero de √©pocas define quantas vezes o modelo vai percorrer todo o conjunto de dados de treinamento. Neste caso, o modelo ser√° treinado por 50 √©pocas, ou seja, 50 itera√ß√µes sobre todo o conjunto de dados.

- **batch_size=16**: Define o n√∫mero de amostras que ser√£o processadas antes de o modelo atualizar seus pesos. Um `batch_size` de 16 significa que, a cada 16 amostras processadas, o modelo ajusta seus par√¢metros.

- **validation_split=0.1**: Esse par√¢metro reserva 10% dos dados de treinamento para valida√ß√£o durante o treinamento. O modelo ser√° avaliado nesse conjunto de valida√ß√£o a cada √©poca para monitorar seu desempenho e evitar overfitting.
